{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images from the Quick Draw Dataset 2k examples\n",
    "\n",
    "\n",
    "get the data at https://console.cloud.google.com/storage/browser/quickdraw_dataset/full/numpy_bitmap?pli=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Dense, Dropout, Flatten,Input, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.5\n",
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_examples_per_class = 2000\n",
    "\n",
    "classes = ['airplane','alarm clock','ambulance','angel','ant','anvil','apple','axe',\n",
    "                  'banana','bandage','barn','baseball bat','baseball','basket',\n",
    "                  'basketball','bathtub','beach','bear','beard','bed','bee','belt',\n",
    "                  'bicycle','binoculars','birthday cake','blueberry',\n",
    "                  'book','boomerang','bottlecap','bowtie','bracelet','brain',\n",
    "                  'bread','broom','bulldozer','bus','bush','butterfly','cactus','cake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the image data from scratch\n",
    "\n",
    "Only use if you are downloading the raw data and doing it yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This cell is only if you are loading the data from scratch\n",
    "# get the data \n",
    "quickdraws = [np.load(\"../../data/{}.npy\".format(qdraw))[:num_examples_per_class] for qdraw in classes]\n",
    "\n",
    "# Concat the arrays together\n",
    "x_data = np.concatenate(quickdraws,axis=0)\n",
    "\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('x_data_40_classes_2k.npy',x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this cell to load the premade datasets that I made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.load(\"./data/x_data_40_classes_2k.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets make some labels for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [np.full((num_examples_per_class,), classes.index(qdraw)) for qdraw in classes]\n",
    "\n",
    "## Concat the arrays together\n",
    "y_data = np.concatenate(labels,axis=0)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 784)\n",
      "(80000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lets look at the Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_object(obj):\n",
    "    # Reshape 784 array into 28x28 image\n",
    "    image = obj.reshape([28,28])\n",
    "    fig, axes = plt.subplots(1, )\n",
    "    fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "    plt.imshow(image, cmap='gray_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADxJJREFUeJzt3VuMHPWVx/HfwRhjgy+AB8v4Nr4RZCOtgxoEXrTKik1E\nIBLkAQQPK4OidRDZaCNFsAgkrx94QCtChMQq0mSx4qyyBFBA+MHiYhPkDTLIbZtwCQt4xwZ7ZDNj\nmYsHYWDssw9TjgaY+lfTXd3V4/P9SKPprtP/7qO2f9OXf1X9zd0FIJ7Tqm4AQDUIPxAU4QeCIvxA\nUIQfCIrwA0ERfiAowg8ERfiBoE7v5IPNnj3be3t7O/mQQCj79u3T4cOHrZHbthR+M7ta0oOSJkn6\nT3e/L3X73t5e1ev1Vh4SQEKtVmv4tk2/7TezSZL+Q9L3Ja2QdLOZrWj2/gB0Viuf+S+TtMfd+939\nc0m/l3RdOW0BaLdWwj9P0v4x1w9k277EzNaaWd3M6kNDQy08HIAytf3bfnfvc/eau9d6enra/XAA\nGtRK+AckLRhzfX62DcAE0Er4d0habmaLzewMSTdJ2lROWwDarempPncfMbN/lvSMRqf6Nrj7G6V1\nBqCtWprnd/fNkjaX1AuADmL3XiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGg\nCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiB\noAg/EBThB4JqaZVeM9sn6aik45JG3L1WRlNAGQYHB3Nrw8PDybGzZs1K1mfOnJmsT5o0KVnvBi2F\nP/P37n64hPsB0EG87QeCajX8LmmLme00s7VlNASgM1p923+luw+Y2fmSnjOz/3X3bWNvkP1RWCtJ\nCxcubPHhAJSlpVd+dx/Ifg9KelLSZePcps/da+5e6+npaeXhAJSo6fCb2VlmNv3kZUnfk/R6WY0B\naK9W3vbPkfSkmZ28n/9296dL6QpA2zUdfnfvl/Q3JfbSVocOHUrWt2zZkqy/9dZbubW33347Obao\nXqS3t7fp+uLFi5Njjx8/nqyPjIwk6x999FGyvn///tzae++9lxw7MDDQ9H1L0rFjx5L1dpo9e3ay\nftttt+XW7rzzzuTY6dOnN9XTVzHVBwRF+IGgCD8QFOEHgiL8QFCEHwiqjKP6Omb37t25tXXr1iXH\nPv10eheEoimtKVOm5NaWLVuWHHvhhRcm60WHf/b39yfr27Zty60dOXIkObZVU6dOTdYXLVqUW5s/\nf35y7OrVq5u+76L7nzFjRnJs0RTmhx9+mKzX6/Vk/d57782tzZ07Nzn29ttvT9YbxSs/EBThB4Ii\n/EBQhB8IivADQRF+ICjCDwQ1oeb5H3jggdzaCy+8kBx7zz33JOs33XRTsr58+fLcWjefpvno0aPJ\n+i233JKs79ixI1kvOiw3qq1btybrjz/+eG5t5cqVZbczLl75gaAIPxAU4QeCIvxAUIQfCIrwA0ER\nfiCoCTXPn1J0bPj69etbuv9PPvkkt5Y61l+STj+9uqe56DTPK1asSNY3b95cZjthbN++PVmfPHly\nbu3SSy8tu51x8coPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0EVTkCb2QZJP5A06O4XZ9vOlfSopF5J\n+yTd6O4ftK/NUanj5k+cOJEc+/zzzyfr999/f7L+zDPP5NZOOy39N3TBggXJetEy2kuXLk3Wb731\n1tzaFVdckRw7Z86cZL1omeui89vPnDkzWT9VDQ8PJ+up9Q6mTZtWdjvjauSV/zeSrv7KtrskbXX3\n5ZK2ZtcBTCCF4Xf3bZK+uuzLdZI2Zpc3Srq+5L4AtFmzn/nnuPvB7PIhSen3jgC6Tstf+Lm7S/K8\nupmtNbO6mdWHhoZafTgAJWk2/O+b2VxJyn4P5t3Q3fvcvebutZ6eniYfDkDZmg3/JklrsstrJD1V\nTjsAOqUw/Gb2iKTtkr5lZgfM7EeS7pP0XTN7R9I/ZNcBTCCF8/zufnNO6aqSeymUmk8fGRlJjn3o\noYeS9f7+/mR93bp1ubWi8/YX3ffevXuT9WeffTZZX7ZsWW6taJ7//PPPT9aLFH2PE3We/4wzzkjW\nP//88w51ko89/ICgCD8QFOEHgiL8QFCEHwiK8ANBTahTd7dySO8TTzxRdjunhNQppBvxxRdflNTJ\nqaXoeWWqD0BlCD8QFOEHgiL8QFCEHwiK8ANBEX4gqDDz/Bhf0eHIRY4fP15SJ6eWokN6U/9fi57T\nVv/NTuKVHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCmlDz/KlTdzPf3Jyi5cWLsH/F+Fo5T0LRORKY\n5wfQEsIPBEX4gaAIPxAU4QeCIvxAUIQfCKpwnt/MNkj6gaRBd78427Ze0j9JOrk+893uvrldTZ50\n+un57TLP35xW54yZ5x9f0fH8KUXn9D/zzDObvu+xGnnl/42kq8fZ/kt3X5X9tD34AMpVGH533ybp\nSAd6AdBBrXzm/6mZvWpmG8zsnNI6AtARzYb/V5KWSFol6aCkX+Td0MzWmlndzOpDQ0N5NwPQYU2F\n393fd/fj7n5C0q8lXZa4bZ+719y91tPT02yfAErWVPjNbO6Yqz+U9Ho57QDolEam+h6R9B1Js83s\ngKR/k/QdM1slySXtk/TjNvYIoA0Kw+/uN4+z+eE29FJoeHg4t1bW3Gc0rc7zj4yMlNTJqaWd8/xl\nYQ8/ICjCDwRF+IGgCD8QFOEHgiL8QFAT6tTd/f39ubUlS5Z0sJNTB6fubg+m+gB0LcIPBEX4gaAI\nPxAU4QeCIvxAUIQfCGpCzfPv2bMnt3bttdcmx+7evTtZP3ToULKeOpz4448/To4tWnJ53rx5yfrl\nl1+erLdyhiRO3d0en332WdNjp0yZUmIn+XjlB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgumqe/9ix\nY8n6wMBAbu3RRx9Nju3r62uqp4kgdS6D1atXJ8eed955LT120T4MrYwt2oegU/PhzShami613Pw5\n53Rm6Ute+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqMJ5fjNbIOm3kuZIckl97v6gmZ0r6VFJvZL2\nSbrR3T9opZkHH3yw6bEXXHBBsv7ww+lVxZcuXZqsz5gxI7d29tlnJ8dOnjw5WU+dp0CSXnrppWT9\n5Zdfzq29+OKLybF79+5N1otcddVVyXrqfAFF+3UUPW8rV65M1i+55JLc2vLly5Nji5Z8nzZtWrJe\n9G+W2r+i1bUUGtXIo4xI+rm7r5B0uaSfmNkKSXdJ2uruyyVtza4DmCAKw+/uB919V3b5qKQ3Jc2T\ndJ2kjdnNNkq6vl1NAijfN3p/YWa9kr4t6WVJc9z9YFY6pNGPBQAmiIbDb2ZnS/qDpJ+5+5dOWufu\nrtHvA8Ybt9bM6mZWL9rfGUDnNBR+M5us0eD/zt2fyDa/b2Zzs/pcSYPjjXX3PnevuXutlRNNAihX\nYfjNzCQ9LOlNd39gTGmTpDXZ5TWSniq/PQDtYqPv2BM3MLtS0v9Iek3SyWMs79bo5/7HJC2U9K5G\np/qOpO6rVqt5vV7Prb/77rvJXu64447cWtEhu7NmzUrWozpw4ECyfsMNNyTrCxcuTNYvuuii3Nr0\n6dOTYz/99NNkfefOncn6rl27cmv79+9Pjm231OnYt2/f3vT91mo11et1a+S2hfP87v4nSXl3lp7k\nBdC12MMPCIrwA0ERfiAowg8ERfiBoAg/EFRXnbp70aJFyfpjjz3WoU7imD9/frLeypzzRFa0j0HR\n4cgffJA+ur0b9nbllR8IivADQRF+ICjCDwRF+IGgCD8QFOEHguqqeX6gW0ydOrWleqeW2W4Fr/xA\nUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVGH4zWyB\nmf3RzP5iZm+Y2b9k29eb2YCZvZL9XNP+dgGUpZGTeYxI+rm77zKz6ZJ2mtlzWe2X7n5/+9oD0C6F\n4Xf3g5IOZpePmtmbkua1uzEA7fWNPvObWa+kb0t6Odv0UzN71cw2mNm45y0ys7VmVjez+tDQUEvN\nAihPw+E3s7Ml/UHSz9z9Y0m/krRE0iqNvjP4xXjj3L3P3WvuXuuG9ckAjGoo/GY2WaPB/527PyFJ\n7v6+ux939xOSfi3psva1CaBsjXzbb5IelvSmuz8wZvvcMTf7oaTXy28PQLs08m3/30r6R0mvmdkr\n2ba7Jd1sZqskuaR9kn7clg4BtEUj3/b/SZKNU9pcfjsAOoU9/ICgCD8QFOEHgiL8QFCEHwiK8ANB\nEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GZu3fuwcyGJL07ZtNsSYc71sA30629dWtfEr01\nq8zeFrl7Q+fL62j4v/bgZnV3r1XWQEK39tatfUn01qyqeuNtPxAU4QeCqjr8fRU/fkq39tatfUn0\n1qxKeqv0Mz+A6lT9yg+gIpWE38yuNrO3zGyPmd1VRQ95zGyfmb2WrTxcr7iXDWY2aGavj9l2rpk9\nZ2bvZL/HXSatot66YuXmxMrSlT533bbidcff9pvZJElvS/qupAOSdki62d3/0tFGcpjZPkk1d698\nTtjM/k7SsKTfuvvF2bZ/l3TE3e/L/nCe4+7/2iW9rZc0XPXKzdmCMnPHriwt6XpJt6jC5y7R142q\n4Hmr4pX/Mkl73L3f3T+X9HtJ11XQR9dz922Sjnxl83WSNmaXN2r0P0/H5fTWFdz9oLvvyi4flXRy\nZelKn7tEX5WoIvzzJO0fc/2AumvJb5e0xcx2mtnaqpsZx5xs2XRJOiRpTpXNjKNw5eZO+srK0l3z\n3DWz4nXZ+MLv665091WSvi/pJ9nb267ko5/Zumm6pqGVmztlnJWl/6rK567ZFa/LVkX4ByQtGHN9\nfratK7j7QPZ7UNKT6r7Vh98/uUhq9nuw4n7+qptWbh5vZWl1wXPXTSteVxH+HZKWm9liMztD0k2S\nNlXQx9eY2VnZFzEys7MkfU/dt/rwJklrsstrJD1VYS9f0i0rN+etLK2Kn7uuW/Ha3Tv+I+kajX7j\n/3+S7qmih5y+lkj6c/bzRtW9SXpEo28Dv9DodyM/knSepK2S3pG0RdK5XdTbf0l6TdKrGg3a3Ip6\nu1Kjb+lflfRK9nNN1c9doq9Knjf28AOC4gs/ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANB/T92\nA7ivDbMYpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122bc2e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "book\n"
     ]
    }
   ],
   "source": [
    "show_object(x_data[53000])\n",
    "print(y_data[53000])\n",
    "print (classes[y_data[53000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffling function\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data,y_data = unison_shuffled_copies(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5SdyiuUncur/AAuZIvh0dknyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129d335c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "blueberry\n"
     ]
    }
   ],
   "source": [
    "show_object(x_data[0])\n",
    "print (y_data[0])\n",
    "print (classes[y_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (64000, 28, 28, 1)\n",
      "64000 train samples\n",
      "16000 test samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2 )\n",
    "\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "num_classes = 40\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Inp=Input(shape=input_shape)\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation='relu',name = 'Conv_01')(Inp)\n",
    "x = Conv2D(64, (3, 3), activation='relu',name = 'Conv_02')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool_01')(x)\n",
    "x = Dropout(0.25,name = 'Dropout_01')(x)\n",
    "x = Flatten(name = 'Flatten_01')(x)\n",
    "x = Dense(128, activation='relu',name = 'Dense_01')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5,name = 'Dropout_02')(x)\n",
    "output = Dense(num_classes, activation='softmax',name = 'Dense_02')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Inp = Input(shape=input_shape,name = 'Input_layer')\n",
    "\n",
    "#ConvBlock 01\n",
    "conv01 = Conv2D(32, (3, 3), padding='same',activation = 'relu', input_shape=Inp.shape,name = 'Conv01_layer')(Inp)\n",
    "conv02 = Conv2D(32, (3, 3),activation = 'relu',name = 'Conv02_layer')(conv01)\n",
    "maxpool_01 = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool01_layer')(conv02)\n",
    "drop01 = BatchNormalization()(maxpool_01)\n",
    "#drop01 = Dropout(0.25,name = 'Dropout01_layer')(drop01)\n",
    "\n",
    "#Convblock 02\n",
    "conv03 = Conv2D(64, (3, 3), padding='same',activation = 'relu',name = 'Conv03_layer')(drop01)\n",
    "conv04 = Conv2D(64, (3, 3),activation = 'relu',name = 'Conv04_layer')(conv03)\n",
    "maxpool_02 = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool02_layer')(conv04)\n",
    "drop02 = BatchNormalization()(maxpool_02)\n",
    "drop02 = Dropout(0.25,name = 'Dropout02_layer')(drop02)\n",
    "\n",
    "\n",
    "# Fully Connected Dense block\n",
    "x = Flatten(name = 'Flatten_layer')(drop02)\n",
    "x = Dense(512, activation='relu',name = 'Dense01_layer')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5,name = 'Dropout03_layer')(x)\n",
    "logits_layer = Dense(num_classes, name= 'logits_layer')(x)\n",
    "output = Activation('softmax',name = 'Sofftmax_layer')(logits_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(Inp,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv01_layer (Conv2D)        (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "Conv02_layer (Conv2D)        (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "MaxPool01_layer (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 13, 13, 32)        128       \n",
      "_________________________________________________________________\n",
      "Conv03_layer (Conv2D)        (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "Conv04_layer (Conv2D)        (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "MaxPool02_layer (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 5, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "Dropout02_layer (Dropout)    (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten_layer (Flatten)      (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "Dense01_layer (Dense)        (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "Dropout03_layer (Dropout)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "logits_layer (Dense)         (None, 40)                20520     \n",
      "_________________________________________________________________\n",
      "Sofftmax_layer (Activation)  (None, 40)                0         \n",
      "=================================================================\n",
      "Total params: 907,656\n",
      "Trainable params: 906,440\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#opt = keras.optimizers.rmsprop()\n",
    "opt = keras.optimizers.Adadelta()\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64000 samples, validate on 16000 samples\n",
      "Epoch 1/10\n",
      "64000/64000 [==============================] - 310s - loss: 2.0135 - acc: 0.4982 - val_loss: 2.3986 - val_acc: 0.3634\n",
      "Epoch 2/10\n",
      "64000/64000 [==============================] - 298s - loss: 1.2654 - acc: 0.6636 - val_loss: 0.9729 - val_acc: 0.7369\n",
      "Epoch 3/10\n",
      "64000/64000 [==============================] - 299s - loss: 1.0461 - acc: 0.7180 - val_loss: 0.8955 - val_acc: 0.7576\n",
      "Epoch 4/10\n",
      "64000/64000 [==============================] - 282s - loss: 0.9242 - acc: 0.7480 - val_loss: 0.8462 - val_acc: 0.7704\n",
      "Epoch 5/10\n",
      "64000/64000 [==============================] - 262s - loss: 0.8344 - acc: 0.7711 - val_loss: 0.8044 - val_acc: 0.7782\n",
      "Epoch 6/10\n",
      "64000/64000 [==============================] - 284s - loss: 0.7685 - acc: 0.7871 - val_loss: 0.7975 - val_acc: 0.7795\n",
      "Epoch 7/10\n",
      "64000/64000 [==============================] - 300s - loss: 0.7239 - acc: 0.7989 - val_loss: 0.7452 - val_acc: 0.7947\n",
      "Epoch 8/10\n",
      "64000/64000 [==============================] - 273s - loss: 0.6774 - acc: 0.8087 - val_loss: 0.7523 - val_acc: 0.7953\n",
      "Epoch 9/10\n",
      "64000/64000 [==============================] - 301s - loss: 0.6423 - acc: 0.8177 - val_loss: 0.7319 - val_acc: 0.7997\n",
      "Epoch 10/10\n",
      "64000/64000 [==============================] - 310s - loss: 0.6089 - acc: 0.8275 - val_loss: 0.7198 - val_acc: 0.8001\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 22s    \n",
      "Model Accuracy = 0.80\n",
      "Model Loss = 0.72\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model with test data set and share sample prediction results\n",
    "evaluation = model.evaluate(x_test, y_test,\n",
    "          batch_size=batch_size)\n",
    "print('Model Accuracy = %.2f' % (evaluation[1]))\n",
    "print('Model Loss = %.2f' % (evaluation[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024594</td>\n",
       "      <td>0.026625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025250</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025344</td>\n",
       "      <td>0.023625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025078</td>\n",
       "      <td>0.024688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025141</td>\n",
       "      <td>0.024438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.025047</td>\n",
       "      <td>0.024813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.024766</td>\n",
       "      <td>0.025937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.025094</td>\n",
       "      <td>0.024625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.025313</td>\n",
       "      <td>0.023750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.025047</td>\n",
       "      <td>0.024813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.025219</td>\n",
       "      <td>0.024125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.026062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.025094</td>\n",
       "      <td>0.024625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.024063</td>\n",
       "      <td>0.028750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.025219</td>\n",
       "      <td>0.024125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.025094</td>\n",
       "      <td>0.024625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.025109</td>\n",
       "      <td>0.024563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.025359</td>\n",
       "      <td>0.023563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.024875</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.025422</td>\n",
       "      <td>0.023312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.025453</td>\n",
       "      <td>0.023187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.024406</td>\n",
       "      <td>0.027375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.024844</td>\n",
       "      <td>0.025625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.024875</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.025031</td>\n",
       "      <td>0.024875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.024813</td>\n",
       "      <td>0.025750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.025156</td>\n",
       "      <td>0.024375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.025172</td>\n",
       "      <td>0.024313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.024641</td>\n",
       "      <td>0.026437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.022437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.024578</td>\n",
       "      <td>0.026687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.024594</td>\n",
       "      <td>0.026625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.024984</td>\n",
       "      <td>0.025063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.024938</td>\n",
       "      <td>0.025250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.025031</td>\n",
       "      <td>0.024875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.024547</td>\n",
       "      <td>0.026812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.024953</td>\n",
       "      <td>0.025188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.025016</td>\n",
       "      <td>0.024938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.025359</td>\n",
       "      <td>0.023563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.025109</td>\n",
       "      <td>0.024563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0   0.024594  0.026625\n",
       "1   0.025250  0.024000\n",
       "2   0.025344  0.023625\n",
       "3   0.025078  0.024688\n",
       "4   0.025141  0.024438\n",
       "5   0.025047  0.024813\n",
       "6   0.024766  0.025937\n",
       "7   0.025094  0.024625\n",
       "8   0.025313  0.023750\n",
       "9   0.025047  0.024813\n",
       "10  0.025219  0.024125\n",
       "11  0.024734  0.026062\n",
       "12  0.025094  0.024625\n",
       "13  0.024063  0.028750\n",
       "14  0.025219  0.024125\n",
       "15  0.025094  0.024625\n",
       "16  0.025109  0.024563\n",
       "17  0.025359  0.023563\n",
       "18  0.024875  0.025500\n",
       "19  0.025422  0.023312\n",
       "20  0.025453  0.023187\n",
       "21  0.024406  0.027375\n",
       "22  0.024844  0.025625\n",
       "23  0.024875  0.025500\n",
       "24  0.025031  0.024875\n",
       "25  0.024813  0.025750\n",
       "26  0.025156  0.024375\n",
       "27  0.025172  0.024313\n",
       "28  0.024641  0.026437\n",
       "29  0.025641  0.022437\n",
       "30  0.024578  0.026687\n",
       "31  0.024594  0.026625\n",
       "32  0.024984  0.025063\n",
       "33  0.024938  0.025250\n",
       "34  0.025031  0.024875\n",
       "35  0.024547  0.026812\n",
       "36  0.024953  0.025188\n",
       "37  0.025016  0.024938\n",
       "38  0.025359  0.023563\n",
       "39  0.025109  0.024563"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(y_train).mean(), pd.DataFrame(y_test).mean()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topn_preds(itemid, n=5):\n",
    "    print (classes[np.where(y_test[itemid]==1)[0][0]])\n",
    "    return (sorted(zip(preds[itemid], classes), reverse=True)[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ant\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.9568345, 'ant'),\n",
       " (0.014659992, 'bandage'),\n",
       " (0.0076032807, 'airplane'),\n",
       " (0.004216772, 'bee'),\n",
       " (0.0026155228, 'bowtie')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topn_preds(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.92013717, 'bus'),\n",
       " (0.022080785, 'ambulance'),\n",
       " (0.016726423, 'bulldozer'),\n",
       " (0.012242624, 'bear'),\n",
       " (0.0082468167, 'bottlecap')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topn_preds(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_preds = preds.argmax(axis=-1)\n",
    "y_true = y_test.argmax(axis=-1)\n",
    "cnf_mat = confusion_matrix(y_preds, y_true )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[371   0   0   2   6   7   0   0   1   1   2   2   1   0   0   1  10   6\n",
      "    1   1   4   2   1   2   0   2   0   1   1   2   2   1   1   2   0   1\n",
      "    0   1   5   0]\n",
      " [  1 317   1   2   0   0  16   0   0   0   1   0   0   0   1   2   1  27\n",
      "    3   0   2   3   0   3   2  28   0   1   2   0   4   3   1   1   0   0\n",
      "    1   2   0   0]\n",
      " [  1   1 320   1   0   3   0   0   0   0   1   0   1   0   0   0   0   1\n",
      "    0   0   0   5   0   1   0   0   0   0   0   0   4   0   0   0  10  20\n",
      "    1   1   0   0]\n",
      " [  1   3   0 333   5   1   0   4   1   1   0   0   2   0   1   0   3   7\n",
      "    0   1   3   0   0   1   1   3   0   0   3   1   4   1   0   1   1   0\n",
      "    0   3   2   1]\n",
      " [  0   3   0   2 313   1   0   0   0   0   1   0   1   1   1   1  10   7\n",
      "    1   2   7   1   0   2   1   3   0   1   0   2   6   0   1   0   1   1\n",
      "    2   5   0   0]\n",
      " [  3   0   0   1   1 351   0   0   0   1   0   1   0   0   0   1   4   1\n",
      "    0   1   0   6   0   0   0   0   0   5   1   0   1   0   3   0   0   0\n",
      "    1   0   0   0]\n",
      " [  0   4   0   0   0   0 367   0   1   0   0   0   0   0   0   0   0   3\n",
      "    0   0   0   0   0   0   2  24   0   1   0   0   0   0   2   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   1   1   1   1   1 341   1   2   0   7   2   2   1   1   1   2\n",
      "    0   0   1   1   0   1   0   0   0   4  10   1   3   1   2   2   1   0\n",
      "    0   0   2   0]\n",
      " [  0   0   0   0   1   0   0   0 343   2   0   3   0   1   0   2   1   0\n",
      "    1   0   0   0   0   0   0   0   0  30   0   2   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  2   2   2   1   2   1   0   2   0 317   2   3   0   0   0   0   0   1\n",
      "    2   1   2   6   0   3   0   0   0   0   0   3   3   2  26   0   1   0\n",
      "    3   0   1   1]\n",
      " [  0   1   0   1   2   3   0   0   0   0 341   0   0   5   1   1   0   0\n",
      "    0   2   1   1   0   1   0   0   2   1   7   1   0   1   8   0   0   2\n",
      "    1   0   3   2]\n",
      " [  1   0   0   0   1   1   0   4   3   0   0 343   5   0   0   1   0   0\n",
      "    0   0   1   1   1   1   0   1   0   3   0   1   0   0   2   3   0   0\n",
      "    0   0   3   0]\n",
      " [  0   1   0   2   0   0   0   1   1   3   0   3 255   3  11   0   0   0\n",
      "    1   0   0   0   0   0   0   8   1   5   2   0   3   4   5   0   0   0\n",
      "    2   1   1   0]\n",
      " [  1   0   2   0   0   2   1   1   0   2   5   1   1 373   6   2   0   1\n",
      "   24   3   3   8   0   1   1   3   4   0  11   0   0   2   2   1   3   4\n",
      "    0   0   1   2]\n",
      " [  0   1   0   0   0   0   0   3   1   0   6   0  95  12 340   1   0   0\n",
      "    5   1   3   2   1   5   0   3   1   1   3   0   5  16   0   0   0   1\n",
      "    1   4   0   2]\n",
      " [  1   1   0   1   1   4   0   0   3   2   0   2   0   5   0 316   5   0\n",
      "    2  10   0   5   0   1   3   1   1   1   6   0   0   1   1   0   0   0\n",
      "    0   0   0   0]\n",
      " [  1   0   0   1   3   0   1   0   0   0   1   0   0   0   0   3 281   1\n",
      "    0   0   1   2   1   0   0   0   0   2   1   1   1   0   0   1   0   2\n",
      "    1   0   0   0]\n",
      " [  6  11   1  10   3   3   3   1   1   3   1   2   0   2   0   1   3 253\n",
      "    4   0   5   0   1   4   2  12   0   1   7   2   3   2   1   0   1   1\n",
      "    7   0   4   0]\n",
      " [  0   2   0   1   0   0   0   0   5   5   1   2   0   9   1   2   0   6\n",
      "  324   0   1   3   1   3   0   3   2   1   1   1   6   6   4   0   2   1\n",
      "    5   0   3   1]\n",
      " [  3   0   1   1   2   1   1   8   0   4   2   5   1   0   3  18   7   5\n",
      "    2 322   0   3   0   1   0   0   3   0   1   2   1   1   4   1   2   1\n",
      "    2   0   0   0]\n",
      " [ 11   4   0   8  14   0   0   0   1   8   1   1   0   3   3   1   1   5\n",
      "    0   0 308   1   3   3   1   6   1   0   2   1   3   0   4   2   4   1\n",
      "    5   4   3   0]\n",
      " [  6   0   3   2   4   4   0   3   1  13   2   8   1   2   0   3  31   3\n",
      "    5   3   2 344   1   2   1   0   0   1  10   5  15   3   4   3   1   2\n",
      "    3   0   0   1]\n",
      " [  0   1   0   1   1   0   1   0   0   0   0   1   0   2   1   1   1   1\n",
      "    0   0   1   2 374   2   1   7   0   0   0   1   1   0   1   0   6   0\n",
      "    0   0   0   0]\n",
      " [  1   1   2   2   4   2   1   1   1   2   1   1   6   4   3   2   1   6\n",
      "    3   0   0   5  11 337   0  16   2   8   3   6   4   3   9   0   7   3\n",
      "    4   3   3   0]\n",
      " [  0   2   1   0   0   0   1   0   1   0   1   0   0   0   0   2   0   0\n",
      "    0   0   0   0   0   0 186   3   1   0   0   0   0   0   0   1   0   0\n",
      "    0   1   2  98]\n",
      " [  1   7   0   1   2   1  14   0   0   2   0   2   0   2   3   0   1   2\n",
      "    1   0   3   1   2   1   2 234   0   2   2   0   8   6   3   0   1   0\n",
      "    3   1   0   0]\n",
      " [  0   2   3   1   1   1   0   2   0   0   5   0   0   2   0   0   0   0\n",
      "    3   3   0   2   0   1   0   1 352   1   1   2   1   4  10   1   0   0\n",
      "    0   0   0   0]\n",
      " [  1   0   0   0   1   0   0   3   6   0   0   2   0   0   0   0   0   1\n",
      "    1   0   0   1   0   0   0   0   0 303   0   0   1   2   1   0   0   0\n",
      "    0   0   0   0]\n",
      " [  2   1   0   2   1   2   2   4   3   1   1   2   1   7   2   6   3  12\n",
      "    1   6   0   5   1   1   4   4   2   2 275   2  19   1   7   1   1   0\n",
      "    9   0   1   2]\n",
      " [  1   0   0   0   4   0   0   2   1   1   0   2   2   1   0   1   1   0\n",
      "    0   0   0   1   0   2   0   2   0   3   0 315   1   1   2   0   2   0\n",
      "    3   5   1   0]\n",
      " [  0   3   1   0   2   0   1   2   1   1   0   1   7   1   3   1   1   5\n",
      "    4   3   0  13   1   2   1   9   4   3  31   1 303   4   4   2   0   0\n",
      "    9   1   0   1]\n",
      " [  0   5   4   1   0   1   1   0   0   7   0   2   5   4   4   2   2   7\n",
      "    5   1   3   5   0  11   1  14   4   1  10   0   3 327   8   0   3   0\n",
      "   39   1   3   4]\n",
      " [  1   0   1   1   0   1   0   0   1   5   3   4   3   2   1   3   0   3\n",
      "    4   2   0   1   0   0   0   4   2   4   9   2   4   3 274   1   0   0\n",
      "    3   0   0   1]\n",
      " [  0   0   1   0   6   0   1   8   2   2   0  10   1   1   0   3   0   0\n",
      "    2   0   1   3   0   1   0   3   0   0   3   1   3   0   2 374   0   0\n",
      "    1   0   2   0]\n",
      " [  5   1   6   1   2   3   0   0   0   3   2   3   2   2   0   3   4   3\n",
      "    2   3   5   1   5   8   4   4   1   1   3   1   1   1   0   3 338   1\n",
      "    8   1   1   3]\n",
      " [  0   2  24   0   0   0   0   0   0   1   0   0   1   2   0   2   4   1\n",
      "    0   4   0   0   3   2   0   0   0   1   7   0   1   0   1   0   5 387\n",
      "    2   0   0   0]\n",
      " [  1   3   2   0   5   2   0   2   0   3   4   2   1   4   0   2  15   2\n",
      "    4   0   5   1   1   4   0   8   0   0   5   0   8  26   4   1   4   1\n",
      "  284   1   3   1]\n",
      " [  1   0   1  11   2   0   3   0   0   1   0   0   0   0   0   0   0   2\n",
      "    2   0   7   0   2   1   0   5   3   0   0   3   2   1   1   0   0   0\n",
      "    3 364   3   0]\n",
      " [  2   2   0   3   1   1   0   2   1   2   1   2   0   0   0   1   1   2\n",
      "    1   0   2   2   0   0   0   0   0   1   1   0   3   2   2   3   0   0\n",
      "    0   0 330   1]\n",
      " [  1   3   1   1   0   0   0   0   0   2   1   0   0   8   0   8   1   1\n",
      "    0   4   0   1   0   0 185   1   4   0   5   0   0   1   1   0   4   0\n",
      "    0   0   0 272]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "print(cnf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'birthday cake'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[-16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tfkeras]",
   "language": "python",
   "name": "conda-env-tfkeras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
